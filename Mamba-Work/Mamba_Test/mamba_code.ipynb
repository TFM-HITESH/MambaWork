{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\New-Hitesh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from model import Mamba, ModelArgs\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# One of:\n",
    "#     'state-spaces/mamba-2.8b-slimpj'\n",
    "#     'state-spaces/mamba-2.8b'\n",
    "#     'state-spaces/mamba-1.4b'\n",
    "#     'state-spaces/mamba-790m'\n",
    "#     'state-spaces/mamba-370m'\n",
    "#     'state-spaces/mamba-130m'\n",
    "pretrained_model_name = 'state-spaces/mamba-790m'\n",
    "\n",
    "model = Mamba.from_pretrained(pretrained_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def generate(model,\n",
    "             tokenizer,\n",
    "             prompt: str,\n",
    "             n_tokens_to_gen: int = 50,\n",
    "             sample: bool = True,\n",
    "             top_k: int = 40):\n",
    "    model.eval()\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "    \n",
    "    for token_n in range(n_tokens_to_gen):\n",
    "        with torch.no_grad():\n",
    "            indices_to_input = input_ids\n",
    "            next_token_logits = model(indices_to_input)[:, -1]\n",
    "        \n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        (batch, vocab_size) = probs.shape\n",
    "        \n",
    "        if top_k is not None:\n",
    "            (values, indices) = torch.topk(probs, k=top_k)\n",
    "            probs[probs < values[:, -1, None]] = 0\n",
    "            probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        if sample:\n",
    "            next_indices = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            next_indices = torch.argmax(probs, dim=-1)[:, None]\n",
    "        \n",
    "        input_ids = torch.cat([input_ids, next_indices], dim=1)\n",
    "\n",
    "    output_completions = [tokenizer.decode(output.tolist()) for output in input_ids][0]\n",
    "    \n",
    "    return output_completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 130 Million Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba is the most successful Mamba that has ever entered the game. After his amazing win over the Brazilian Mamba in Mombasa, he had only two more goals to his name the following week.\n",
      "\n",
      "Mamba got his first call up to the M\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'Mamba is the')) #130m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John: Hi!\n",
      "Sally: Hey!\n",
      "John: This is Sally! (He's smiling a little at the show!)\n",
      "(I also think we made up. Not sure!)\n",
      "Sally: Hey there, John. I think it’s nice of us to introduce\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'John: Hi!\\nSally:')) #130m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def reverse_string() {\n",
      "  return \"Hello\" :\n",
      "}\n",
      "\n",
      "And then my custom implementation of StringToHash:\n",
      "private static StringToHash<String> getMessage(String message) {\n",
      "  return (Message) MessageUtils.fromMessageBody\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'def reverse_string()')) #130m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is \n",
      "not defined \n",
      "by some simple definition \n",
      "or by some one-on-one interaction. \n",
      "If we are discussing philosophy, \n",
      "we are talking about the meaning of life. If we are discussing \n",
      "some other philosophical concept\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'The meaning of life is ')) #130m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 790 Million Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is \n",
      "you need to realize that we are only here a few times. \n",
      "That's all. (laughs)\n",
      "The world is here and gone.\n",
      "You don’t need to know.\n",
      "\n",
      "Russian: \n",
      "Поверь\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'The meaning of life is ')) #790m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitesh is interning at ithink.io in New Delhi. Previously, he worked on Android for Google and iOS for Tata and NCR. He hails from Mumbai, is from an NGO and loves programming. He is an enthusiastic fan of both his dog and apple\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'Hitesh is interning at ')) #790m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitesh is an intern. Elaborate on this. Invent necessary details in front of the interviewer in front of you. Be bold with what you do.\n",
      "\n",
      "Ask the interviewer a question he/she probably would have liked to have asked you. Be honest: the interviewer should be honest and expect questions\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'Hitesh is an intern. Elaborate on this. Invent necessary details')) #790m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dog, a cat and a sheep walked into \n",
      "a barn.\n",
      "Who would be the cat, the sheep or the dog?\n",
      "The cat, because the cat is bigger than the sheep.\n",
      "The dog, because the dog is better at hunting.\n",
      "The sheep, because it lives in\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'A dog, a cat and a sheep walked into ')) #790m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a joke.........................?\"\n",
      "\n",
      "\"Oh I'm sorry....that's what you think? How many jokes I think that I can tell!.....I can't hear any one! I wish i could say 'I can tell any joke with any story\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, 'Tell me a joke ')) #790m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
